{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN_faceRecognition_lfw_data.ipynb","provenance":[{"file_id":"1C_MQ0PBmDOw9hL4WZQCc09ANObdVSFyL","timestamp":1576001304218},{"file_id":"1aywihGBcctJ7hFXYTjoVhrQfNy2jWD92","timestamp":1574384375780},{"file_id":"1tRfEI5Om9tmZDBmJat3o_Cq9bb3yfi9o","timestamp":1572563332093},{"file_id":"1VlmgpgO9z8GoLc0PFUpuDCxRNMnEaSgr","timestamp":1572056470317}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"e62CqQC4_GC-","colab_type":"code","colab":{}},"source":["#Please re-run if it crashes\n","import numpy\n","import numpy as np\n","from google.colab import drive\n","\n","from scipy.stats import norm\n","\n","import keras\n","from keras import layers\n","from keras.models import Model\n","from keras import metrics\n","from keras import backend as K   # 'generic' backend so code works with either tensorflow or theano\n","\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.layers import Activation, Dropout, Flatten, Dense\n","from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XgqWAHi5oGMG","colab_type":"code","outputId":"11b2416f-9928-4cdc-cc68-14fa203add96","executionInfo":{"status":"ok","timestamp":1575143627327,"user_tz":360,"elapsed":1449,"user":{"displayName":"Benjamin Choi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAop0HAZ44OnxgjobTo-eMJEgFqhtg5mJK_996p=s64","userId":"02174246971749571164"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["drive.mount('/content/drive', force_remount = True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mpM5XsjUFoie","colab_type":"code","colab":{}},"source":["# dimensions of our images.\n","img_width, img_height = 250, 250\n","\n","train_data_dir = '/content/drive/My Drive/Colab Notebooks/data/train'\n","validation_data_dir = '/content/drive/My Drive/Colab Notebooks/data/validation'\n","nb_train_samples = 1139\n","nb_validation_samples = 100\n","epochs = 5\n","batch_size = 16\n","\n","if K.image_data_format() == 'channels_first':\n","    input_shape = (3, img_width, img_height)\n","else:\n","    input_shape = (img_width, img_height, 3)\n","\n","#input_shape = Lambda(lambda x: tf.image.rgb_to_grayscale(x))\n","\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Opzwf4L-OTjq","colab_type":"code","colab":{}},"source":["model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n","model.add(Dense(64))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(1))\n","model.add(Activation('sigmoid'))\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HPmCrE2-OTpD","colab_type":"code","outputId":"05c8d31b-4e11-46e0-feca-fbc72546aaff","executionInfo":{"status":"ok","timestamp":1575143627648,"user_tz":360,"elapsed":1732,"user":{"displayName":"Benjamin Choi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAop0HAZ44OnxgjobTo-eMJEgFqhtg5mJK_996p=s64","userId":"02174246971749571164"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["# this is the augmentation configuration we will use for training\n","train_datagen = ImageDataGenerator(\n","        rescale=1./255,\n","        shear_range=0.2,\n","        zoom_range=0.2,\n","        horizontal_flip=True)\n","\n","# this is the augmentation configuration we will use for testing:\n","# only rescaling\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# this is a generator that will read pictures found in\n","# subfolers of 'data/train', and indefinitely generate\n","# batches of augmented image data\n","train_generator = train_datagen.flow_from_directory(\n","        train_data_dir,  # this is the target directory\n","        target_size=(img_width, img_height),  # all images will be resized to 150x150\n","        #color_mode='grayscale',\n","        batch_size=batch_size,\n","        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n","\n","# this is a similar generator, for validation data\n","validation_generator = test_datagen.flow_from_directory(\n","        validation_data_dir,\n","        target_size=(img_width, img_height),\n","        batch_size=batch_size,\n","        class_mode='binary')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 1119 images belonging to 2 classes.\n","Found 100 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tb2ydaa8lK1R","colab_type":"code","outputId":"fb65d0bc-b580-425f-80f2-e4d22aaffd9d","executionInfo":{"status":"ok","timestamp":1575143699489,"user_tz":360,"elapsed":73564,"user":{"displayName":"Benjamin Choi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAop0HAZ44OnxgjobTo-eMJEgFqhtg5mJK_996p=s64","userId":"02174246971749571164"}},"colab":{"base_uri":"https://localhost:8080/","height":185}},"source":["model.fit_generator(\n","        train_generator,\n","        steps_per_epoch=nb_train_samples // batch_size,\n","        epochs=epochs,\n","        validation_data=validation_generator,\n","        validation_steps=nb_validation_samples // batch_size)\n","model.save_weights('/content/drive/My Drive/Colab Notebooks/faceWeights.h5')  # always save your weights after training or during training"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","71/71 [==============================] - 14s 201ms/step - loss: 0.7274 - acc: 0.5860 - val_loss: 0.6947 - val_acc: 0.5104\n","Epoch 2/5\n","71/71 [==============================] - 14s 203ms/step - loss: 0.6462 - acc: 0.6434 - val_loss: 0.5876 - val_acc: 0.6905\n","Epoch 3/5\n","71/71 [==============================] - 14s 197ms/step - loss: 0.5681 - acc: 0.7065 - val_loss: 0.6894 - val_acc: 0.5595\n","Epoch 4/5\n","71/71 [==============================] - 14s 202ms/step - loss: 0.4681 - acc: 0.7867 - val_loss: 0.4870 - val_acc: 0.7738\n","Epoch 5/5\n","71/71 [==============================] - 14s 197ms/step - loss: 0.3939 - acc: 0.8404 - val_loss: 0.4868 - val_acc: 0.7976\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c4WL9I7KyNvY","colab_type":"code","outputId":"70df2238-070d-48d8-d60a-6c72feb8110c","executionInfo":{"status":"ok","timestamp":1575143794923,"user_tz":360,"elapsed":585,"user":{"displayName":"Benjamin Choi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAop0HAZ44OnxgjobTo-eMJEgFqhtg5mJK_996p=s64","userId":"02174246971749571164"}},"colab":{"base_uri":"https://localhost:8080/","height":67}},"source":["from sklearn.metrics import classification_report, confusion_matrix\n","import numpy\n","\n","test_data_dir = '/content/drive/My Drive/Colab Notebooks/data/test'\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","#batch_input = np.zeros((1,) + (250, 250, 3), dtype=K.floatx())\n","#img_input = img_to_array(load_img(test_data_dir))\n","#batch_input[0] = img_input\n","\n","#test_data_dir = test_data_dir.reshape(img_width, img_height)\n","test_generator = test_datagen.flow_from_directory(\n","        #batch_input,\n","        test_data_dir,\n","        target_size=(img_width, img_height),\n","        #color_mode=\"grayscale\",\n","        shuffle = False,\n","        class_mode='categorical',\n","        batch_size=1)\n","\n","filenames = test_generator.filenames\n","nb_samples = len(filenames)\n","\n","predict = model.predict_generator(test_generator,steps = nb_samples)\n","\n","y_pred = numpy.rint(predict)\n","y_true = test_generator.classes\n","print (confusion_matrix(y_true, y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 40 images belonging to 2 classes.\n","[[18  2]\n"," [ 6 14]]\n"],"name":"stdout"}]}]}